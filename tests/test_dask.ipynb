{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "    from poser import *\n",
       "\n",
       "    import toolz\n",
       "\n",
       "    \n",
       "    def to_delayed(f, *args, delayed=None, **kwargs):\n",
       "        import functools, typing\n",
       "        import poser, importlib\n",
       "        import dask.bag.random, toolz\n",
       "        Delayed =__import__(\"importlib\").import_module('dask.delayed').Delayed\n",
       "\n",
       "        function_mapping = {\n",
       "            all: dask.bag.Bag.all,\n",
       "            any: dask.bag.Bag.any,\n",
       "            map: dask.bag.Bag.map,\n",
       "            sum: dask.bag.Bag.sum,\n",
       "            toolz.itertoolz.take: dask.bag.Bag.take,\n",
       "            toolz.itertoolz.count: dask.bag.Bag.count,\n",
       "            toolz.itertoolz.unique: dask.bag.Bag.distinct,\n",
       "            poser.filter: dask.bag.Bag.filter,\n",
       "            __import__(\"_operator\").concat: dask.bag.Bag.flatten,\n",
       "            toolz.sandbox.fold: dask.bag.Bag.fold,\n",
       "            \"frequencies\": dask.bag.Bag.frequencies,\n",
       "            toolz.itertoolz.groupby: dask.bag.Bag.groupby,\n",
       "            toolz.itertoolz.join: dask.bag.Bag.join,\n",
       "            poser.map: dask.bag.Bag.map,\n",
       "            \"map_partitions\": dask.bag.Bag.map_partitions,\n",
       "            max: dask.bag.Bag.max,\n",
       "            __import__(\"statistics\").mean: dask.bag.Bag.mean,\n",
       "            min: dask.bag.Bag.min,\n",
       "            toolz.itertoolz.pluck: dask.bag.Bag.pluck,\n",
       "            __import__(\"itertools\").product: dask.bag.Bag.product,\n",
       "            __import__(\"_functools\").reduce: dask.bag.Bag.reduction,\n",
       "            toolz.itertoolz.random_sample: dask.bag.Bag.random_sample,\n",
       "            toolz.itertoolz.remove: dask.bag.Bag.remove,\n",
       "            \"repartition\": \"\",\n",
       "            __import__(\"itertools\").starmap: dask.bag.Bag.starmap,\n",
       "            __import__(\"statistics\").stdev: dask.bag.Bag.std,\n",
       "            sum: dask.bag.Bag.sum,\n",
       "            toolz.itertoolz.take: dask.bag.Bag.take,\n",
       "            \"to_*\": ...,\n",
       "            toolz.itertoolz.topk: dask.bag.Bag.topk,\n",
       "            __import__(\"statistics\").variance: dask.bag.Bag.var,\n",
       "            \"read_*\": ...,\n",
       "            \"from_\": ...,\n",
       "            \"concat\": dask.bag.concat,\n",
       "            zip: dask.bag.zip,\n",
       "            __import__(\"random\").choices: dask.bag.random.choices,\n",
       "            __import__(\"random\").sample: dask.bag.random.sample,\n",
       "            \"to_*\": ...,\n",
       "        }\n",
       "            \n",
       "        if isinstance(f, λ):\n",
       "            if f.args:\n",
       "                delayed = to_delayed(f.args[0], **f.kwargs)\n",
       "                \n",
       "            for g in list(f):\n",
       "                delayed = to_delayed(g, delayed=delayed)\n",
       "            return delayed\n",
       "        \n",
       "        if isinstance(f, typing.Sequence):\n",
       "            return dask.bag.from_sequence(f, **kwargs)\n",
       "        \n",
       "        if isinstance(f, functools.partial):\n",
       "            f, args, kwargs = f.func, f.args, f.keywords\n",
       "            \n",
       "            \n",
       "        if f in {poser.map, poser.filter}:\n",
       "            [kwargs.pop(x, None) for x in \"key property\".split()]\n",
       "            \n",
       "            \n",
       "        if f in function_mapping:\n",
       "            if delayed is None:\n",
       "                return function_mapping[f](*args, **kwargs)\n",
       "            \n",
       "            if isinstance(delayed, Delayed):\n",
       "                delayed = dask.bag.from_delayed(delayed)\n",
       "\n",
       "            return function_mapping[f](delayed, *args, **kwargs)\n",
       "        k\n",
       "        if delayed is None:\n",
       "            return dask.delayed(f)\n",
       "        \n",
       "        \n",
       "        return dask.delayed(f)(delayed)\n",
       "        \n",
       "            \n",
       "\n",
       "    import poser\n",
       "\n",
       "    λ.delayed = to_delayed\n",
       "    λ.visualize = λ[to_delayed].methodcaller('visualize')\n",
       "    λ.compute = λ[to_delayed].methodcaller('compute')\n",
       "    λ.to_dataframe = λ[to_delayed].methodcaller('to_dataframe')"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    from poser import *\n",
    "\n",
    "    import toolz\n",
    "\n",
    "    \n",
    "    def to_delayed(f, *args, delayed=None, **kwargs):\n",
    "        import functools, typing\n",
    "        import poser, importlib\n",
    "        import dask.bag.random, toolz\n",
    "        Delayed =__import__(\"importlib\").import_module('dask.delayed').Delayed\n",
    "\n",
    "        function_mapping = {\n",
    "            all: dask.bag.Bag.all,\n",
    "            any: dask.bag.Bag.any,\n",
    "            map: dask.bag.Bag.map,\n",
    "            sum: dask.bag.Bag.sum,\n",
    "            toolz.itertoolz.take: dask.bag.Bag.take,\n",
    "            toolz.itertoolz.count: dask.bag.Bag.count,\n",
    "            toolz.itertoolz.unique: dask.bag.Bag.distinct,\n",
    "            poser.filter: dask.bag.Bag.filter,\n",
    "            __import__(\"_operator\").concat: dask.bag.Bag.flatten,\n",
    "            toolz.sandbox.fold: dask.bag.Bag.fold,\n",
    "            \"frequencies\": dask.bag.Bag.frequencies,\n",
    "            toolz.itertoolz.groupby: dask.bag.Bag.groupby,\n",
    "            toolz.itertoolz.join: dask.bag.Bag.join,\n",
    "            poser.map: dask.bag.Bag.map,\n",
    "            \"map_partitions\": dask.bag.Bag.map_partitions,\n",
    "            max: dask.bag.Bag.max,\n",
    "            __import__(\"statistics\").mean: dask.bag.Bag.mean,\n",
    "            min: dask.bag.Bag.min,\n",
    "            toolz.itertoolz.pluck: dask.bag.Bag.pluck,\n",
    "            __import__(\"itertools\").product: dask.bag.Bag.product,\n",
    "            __import__(\"_functools\").reduce: dask.bag.Bag.reduction,\n",
    "            toolz.itertoolz.random_sample: dask.bag.Bag.random_sample,\n",
    "            toolz.itertoolz.remove: dask.bag.Bag.remove,\n",
    "            \"repartition\": \"\",\n",
    "            __import__(\"itertools\").starmap: dask.bag.Bag.starmap,\n",
    "            __import__(\"statistics\").stdev: dask.bag.Bag.std,\n",
    "            sum: dask.bag.Bag.sum,\n",
    "            toolz.itertoolz.take: dask.bag.Bag.take,\n",
    "            \"to_*\": ...,\n",
    "            toolz.itertoolz.topk: dask.bag.Bag.topk,\n",
    "            __import__(\"statistics\").variance: dask.bag.Bag.var,\n",
    "            \"read_*\": ...,\n",
    "            \"from_\": ...,\n",
    "            \"concat\": dask.bag.concat,\n",
    "            zip: dask.bag.zip,\n",
    "            __import__(\"random\").choices: dask.bag.random.choices,\n",
    "            __import__(\"random\").sample: dask.bag.random.sample,\n",
    "            \"to_*\": ...,\n",
    "        }\n",
    "            \n",
    "        if isinstance(f, λ):\n",
    "            if f.args:\n",
    "                delayed = to_delayed(f.args[0], **f.kwargs)\n",
    "                \n",
    "            for g in list(f):\n",
    "                delayed = to_delayed(g, delayed=delayed)\n",
    "            return delayed\n",
    "        \n",
    "        if isinstance(f, typing.Sequence):\n",
    "            return dask.bag.from_sequence(f, **kwargs)\n",
    "        \n",
    "        if isinstance(f, functools.partial):\n",
    "            f, args, kwargs = f.func, f.args, f.keywords\n",
    "            \n",
    "            \n",
    "        if f in {poser.map, poser.filter}:\n",
    "            [kwargs.pop(x, None) for x in \"key property\".split()]\n",
    "            \n",
    "            \n",
    "        if f in function_mapping:\n",
    "            if delayed is None:\n",
    "                return function_mapping[f](*args, **kwargs)\n",
    "            \n",
    "            if isinstance(delayed, Delayed):\n",
    "                delayed = dask.bag.from_delayed(delayed)\n",
    "\n",
    "            return function_mapping[f](delayed, *args, **kwargs)\n",
    "        k\n",
    "        if delayed is None:\n",
    "            return dask.delayed(f)\n",
    "        \n",
    "        \n",
    "        return dask.delayed(f)(delayed)\n",
    "        \n",
    "            \n",
    "\n",
    "    import poser\n",
    "\n",
    "    λ.delayed = to_delayed\n",
    "    λ.visualize = λ[to_delayed].methodcaller('visualize')\n",
    "    λ.compute = λ[to_delayed].methodcaller('compute')\n",
    "    λ.to_dataframe = λ[to_delayed].methodcaller('to_dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "    f = λ(range(100))[\n",
       "        -λ.mod(2) # filter\n",
       "        :λ.mul(10)\n",
       "        :sum\n",
       "    ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    f = λ(range(100))[\n",
    "        -λ.mod(2) # filter\n",
    "        :λ.mul(10)\n",
    "        :sum\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "    fd = λ(range(100), npartitions=6)[\n",
       "        -λ.mod(2) # filter\n",
       "        :λ.mul(10) # map\n",
       "        :sum # reduce\n",
       "    ]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    fd = λ(range(100), npartitions=6)[\n",
    "        -λ.mod(2) # filter\n",
    "        :λ.mul(10) # map\n",
    "        :sum # reduce\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "    fd.visualize(), fd.delayed()\n",
       "    assert fd.compute() == f()"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    fd.visualize(), fd.delayed()\n",
    "    assert fd.compute() == f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/markdown": [
       "    fd = λ(range(100))[\n",
       "        -λ[Λ%2] # filter\n",
       "        :λ[Λ*10]\n",
       "        :sum\n",
       "    ]\n",
       "    fd.compute()"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    fd = λ(range(100))[\n",
    "        -λ[Λ%2] # filter\n",
    "        :λ[Λ*10]\n",
    "        :sum\n",
    "    ]\n",
    "    fd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dask DataFrame Structure:\n",
       "                   type     str   range\n",
       " npartitions=10                        \n",
       "                 object  object  object\n",
       "                    ...     ...     ...\n",
       " ...                ...     ...     ...\n",
       "                    ...     ...     ...\n",
       "                    ...     ...     ...\n",
       " Dask Name: to_dataframe, 40 tasks,\n",
       "                    0              0              0                   0  \\\n",
       " type   <class 'int'>  <class 'int'>  <class 'int'>       <class 'int'>   \n",
       " str                0              2              4                   6   \n",
       " range             ()         (0, 1)   (0, 1, 2, 3)  (0, 1, 2, 3, 4, 5)   \n",
       " \n",
       "                               0                               0  \\\n",
       " type              <class 'int'>                   <class 'int'>   \n",
       " str                           8                              10   \n",
       " range  (0, 1, 2, 3, 4, 5, 6, 7)  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)   \n",
       " \n",
       "                                             0  \\\n",
       " type                            <class 'int'>   \n",
       " str                                        12   \n",
       " range  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)   \n",
       " \n",
       "                                                     0  \\\n",
       " type                                    <class 'int'>   \n",
       " str                                                14   \n",
       " range  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13)   \n",
       " \n",
       "                                                        0  \\\n",
       " type                                       <class 'int'>   \n",
       " str                                                   16   \n",
       " range  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       " \n",
       "                                                        0  \n",
       " type                                       <class 'int'>  \n",
       " str                                                   18  \n",
       " range  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/markdown": [
       "    f = λ(λ.range(20)(), npartitions=10)[\n",
       "        -λ.mod(2) # filter divisible by two.\n",
       "        :λ[{\"type\": type, \"str\": str, \"range\": range}] # map a dictionary\n",
       "    ].to_dataframe(); f\n",
       "\n",
       "    f, f.compute().T"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    f = λ(λ.range(20)(), npartitions=10)[\n",
    "        -λ.mod(2) # filter divisible by two.\n",
    "        :λ[{\"type\": type, \"str\": str, \"range\": range}] # map a dictionary\n",
    "    ].to_dataframe(); f\n",
    "\n",
    "    f, f.compute().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    !gist poser-dask.ipynb -u6bfa54a91a7fd2e9b6f22109119b254a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
